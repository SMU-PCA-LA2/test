{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "DVww--WZS5cP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "645e1db4-137e-41cd-cb66-bce177954a76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 완료!\n",
            "대표 벡터: [-9.53890904e-19  1.69580605e-18 -1.69580605e-18  6.35927269e-19\n",
            " -3.70957574e-18 -5.40538179e-18  1.58981817e-18  3.49759998e-18\n",
            "  4.23951513e-19 -1.13407030e-17  2.64969696e-18 -3.97454543e-18\n",
            " -1.12082181e-17  9.43292116e-18 -5.08741816e-18  6.94220603e-18\n",
            "  7.04819390e-18 -4.66346664e-18 -4.91518785e-18  5.29939391e-18\n",
            " -5.29939391e-19 -1.03868121e-17  4.16002422e-18  6.09430300e-19\n",
            "  6.47850906e-18  4.50448483e-18  1.16586666e-18  6.27978179e-18\n",
            "  6.62424239e-19 -7.31316360e-18  4.84894543e-18  1.19236363e-18\n",
            "  8.42603632e-18 -6.51825451e-18  4.87544240e-18  1.86803635e-18\n",
            "  1.32484848e-18 -3.10014544e-18 -3.60358786e-18 -3.65658180e-18\n",
            " -2.39797575e-18 -1.96077575e-18  8.77049692e-18 -4.61047270e-18\n",
            "  3.12664241e-18  3.07364847e-18 -5.14041209e-18  3.28562423e-18\n",
            " -1.39771514e-18 -1.58981817e-19 -3.97454543e-18 -6.67723633e-18\n",
            "  6.83621815e-18 -4.50448483e-18 -1.41162605e-17 -1.40433939e-18\n",
            "  5.47162421e-18  6.47850906e-18 -6.67723633e-18 -7.94909087e-18\n",
            "  5.24639997e-18  1.02013333e-18  6.68386057e-18 -5.25964846e-18\n",
            "  1.17812151e-17 -1.24535757e-18  8.49227874e-18 -5.07416967e-18\n",
            "  4.76945452e-18  2.64969696e-20  3.44460604e-19 -5.80283633e-18\n",
            "  6.30627876e-18 -7.20717572e-18 -4.14677574e-18 -7.48539390e-19\n",
            " -8.83673935e-18 -7.40755905e-18 -2.41453635e-18  1.52150567e-18\n",
            "  5.73286777e-18  3.37934691e-18  1.01677981e-17  2.32879640e-18\n",
            " -1.91128800e-18  2.65349425e-18 -3.39275711e-19  3.58124721e-18\n",
            " -1.75767544e-18  3.45072570e-18  4.92469929e-18 -3.85551770e-18\n",
            " -5.95725590e-18 -7.32506755e-18  5.42217366e-18  1.34265517e-18\n",
            "  4.20813205e-18  2.32224231e-18  5.47317920e-19  5.89954723e-18\n",
            "  1.61648698e-18 -1.07754476e-17 -6.01294746e-18 -1.21619231e-17\n",
            "  5.49002788e-18  1.24070730e-17 -4.37996997e-19 -1.81298866e-18\n",
            " -3.02938074e-18  7.52320563e-18 -5.38874154e-18  1.63982801e-18\n",
            " -4.94491548e-18  5.02022373e-18 -9.63511096e-20  4.94710437e-18\n",
            "  1.02934998e-17 -1.87088190e-18 -5.22938689e-18 -4.32429471e-18\n",
            " -5.51061664e-18 -7.71194742e-18 -1.08754070e-18  2.81186525e-18\n",
            " -6.22153838e-18  7.48001453e-18  3.23138298e-18 -7.35517431e-18]\n",
            "Confusion Matrix:\n",
            "[[15  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0]\n",
            " [ 0 15  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0]\n",
            " [ 0  0 14  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0]\n",
            " [ 0  0  0  8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0]\n",
            " [ 0  0  0  0 19  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0]\n",
            " [ 0  0  0  0  0 16  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0]\n",
            " [ 0  0  0  0  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0]\n",
            " [ 0  0  0  0  0  0  0 19  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0 19  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0 38  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0 39  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0 16  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  8  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 18  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 24  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0  0  0  0  0  0  0  0\n",
            "   0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 16  0  0  0  0  0  0  0\n",
            "   0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  5  0  0  0  0  0  0\n",
            "   0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0  0  0  0  0\n",
            "   0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 15  0  0  0  0\n",
            "   0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 22  0  0  0\n",
            "   0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 41  0  0\n",
            "   0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 25  0\n",
            "   0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 16\n",
            "   0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  15  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0 18  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0 17]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         CJY       1.00      1.00      1.00        15\n",
            "         CSB       1.00      1.00      1.00        15\n",
            "         CYW       1.00      1.00      1.00        14\n",
            "         JHS       1.00      1.00      1.00         8\n",
            "         JUH       1.00      1.00      1.00        19\n",
            "         KHH       1.00      1.00      1.00        16\n",
            "         KHY       1.00      1.00      1.00        30\n",
            "         KKJ       1.00      1.00      1.00        19\n",
            "         KMG       1.00      1.00      1.00        19\n",
            "         KMJ       1.00      1.00      1.00        38\n",
            "         KMS       1.00      1.00      1.00        39\n",
            "         KRE       1.00      1.00      1.00        16\n",
            "         KUS       1.00      1.00      1.00         8\n",
            "         KYW       1.00      1.00      1.00        18\n",
            "         LDW       1.00      1.00      1.00        24\n",
            "         LGE       1.00      1.00      1.00        18\n",
            "         LJH       1.00      1.00      1.00        16\n",
            "         LSC       1.00      1.00      1.00         5\n",
            "         LSE       1.00      1.00      1.00        18\n",
            "         MJY       1.00      1.00      1.00        15\n",
            "         PIW       1.00      1.00      1.00        22\n",
            "         PJS       1.00      1.00      1.00        41\n",
            "         PSG       1.00      1.00      1.00        25\n",
            "         RYJ       1.00      1.00      1.00        16\n",
            "         SHS       1.00      1.00      1.00        15\n",
            "         YSB       1.00      1.00      1.00        18\n",
            "         YYS       1.00      1.00      1.00        17\n",
            "\n",
            "    accuracy                           1.00       524\n",
            "   macro avg       1.00      1.00      1.00       524\n",
            "weighted avg       1.00      1.00      1.00       524\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import dlib\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import SVC\n",
        "from skimage import io\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "import joblib\n",
        "\n",
        "# dlib의 얼굴 탐지기와 랜드마크 추출기 초기화\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "sp = dlib.shape_predictor('/content/drive/MyDrive/Colab Notebooks/shape_predictor_68_face_landmarks.dat')\n",
        "facerec = dlib.face_recognition_model_v1('/content/drive/MyDrive/Colab Notebooks/dlib_face_recognition_resnet_model_v1.dat')\n",
        "\n",
        "def find_landmarks(img_path):\n",
        "    # 이미지 로드\n",
        "    img = io.imread(img_path)\n",
        "\n",
        "    # 이미지에서 얼굴 탐지\n",
        "    dets = detector(img, 1)\n",
        "\n",
        "    # 얼굴이 없는 경우 빈 배열 반환\n",
        "    if len(dets) == 0:\n",
        "        return np.empty(0, dtype=int)\n",
        "\n",
        "    # 랜드마크 좌표를 저장할 배열 초기화\n",
        "    landmarks = np.zeros((len(dets), 68, 2), dtype=int)\n",
        "    for k, d in enumerate(dets):\n",
        "        # 얼굴 영역에서 랜드마크 추출\n",
        "        shape = sp(img, d)\n",
        "\n",
        "        # dlib shape를 numpy 배열로 변환하여 저장\n",
        "        for i in range(0, 68):\n",
        "            landmarks[k][i] = (shape.part(i).x, shape.part(i).y)\n",
        "\n",
        "    return landmarks\n",
        "\n",
        "def encode_faces(img_path, landmarks):\n",
        "    img = io.imread(img_path)\n",
        "    face_descriptors = []\n",
        "    for landmark in landmarks:\n",
        "        # 얼굴 랜드마크를 dlib.full_object_detection 형태로 변환\n",
        "        shape = dlib.full_object_detection(\n",
        "            dlib.rectangle(0, 0, img.shape[1], img.shape[0]),\n",
        "            [dlib.point(pt[0], pt[1]) for pt in landmark]\n",
        "        )\n",
        "        # 얼굴 랜드마크를 사용하여 얼굴의 특징 벡터 계산\n",
        "        face_descriptor = facerec.compute_face_descriptor(img, shape)\n",
        "        face_descriptors.append(np.array(face_descriptor))\n",
        "\n",
        "    return np.array(face_descriptors)\n",
        "\n",
        "def train_classifier(training_data, labels):\n",
        "    # 얼굴의 특징 벡터 추출\n",
        "    face_descriptors = []\n",
        "    for img_path, landmarks in training_data:\n",
        "        descriptors = encode_faces(img_path, landmarks)\n",
        "        if len(descriptors) > 0:  # 특징 벡터가 존재하는 경우에만 추가\n",
        "            face_descriptors.extend(descriptors)\n",
        "    if len(face_descriptors) == 0:\n",
        "        raise ValueError(\"No valid face descriptors found in training data.\")\n",
        "\n",
        "    face_descriptors = np.array(face_descriptors)\n",
        "\n",
        "    # PCA를 사용하여 특징 벡터 차원 축소\n",
        "    pca = PCA(n_components=128)\n",
        "    reduced_face_descriptors = pca.fit_transform(face_descriptors)\n",
        "\n",
        "    # 대표 벡터 생성\n",
        "    representative_vector = np.mean(reduced_face_descriptors, axis=0)\n",
        "\n",
        "    # 분류기 훈련\n",
        "    classifier = SVC()\n",
        "    classifier.fit(reduced_face_descriptors, labels)\n",
        "\n",
        "    return classifier, pca, representative_vector\n",
        "\n",
        "# 이미지 로드 및 라벨 생성을 위한 부분\n",
        "folder = '/content/drive/MyDrive/Colab Notebooks/linearAlgebra2_face_detection_datasets'\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "for team_folder in os.listdir(folder):\n",
        "    team_folder_path = os.path.join(folder, team_folder)\n",
        "    if os.path.isdir(team_folder_path):\n",
        "        for person_folder in os.listdir(team_folder_path):\n",
        "            person_folder_path = os.path.join(team_folder_path, person_folder)\n",
        "            person_initial = person_folder.split(\"_\")[1]  # 개인 이니셜 추출\n",
        "            if os.path.isdir(person_folder_path):\n",
        "                for image_name in os.listdir(person_folder_path):\n",
        "                    image_path = os.path.join(person_folder_path, image_name) # 이미지 경로\n",
        "                    # 얼굴 랜드마크 찾기\n",
        "                    landmarks = find_landmarks(image_path)\n",
        "                    if len(landmarks) == 1:  # 얼굴이 하나라면\n",
        "                        data.append((image_path, landmarks))\n",
        "                        labels.append(person_initial)\n",
        "                        \"\"\"\n",
        "                    else:\n",
        "                        # 얼굴이 하나가 아닌 경우 경고 출력\n",
        "                        print(f\"얼굴이 하나가 아닌 이미지: {image_path}, 얼굴 개수: {len(landmarks)}\")\n",
        "\"\"\"\n",
        "\n",
        "# 데이터를 학습용과 검증용으로 분리\n",
        "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# 학습기 훈련\n",
        "classifier, pca, representative_vector = train_classifier(train_data, train_labels)\n",
        "\n",
        "# 모델 저장\n",
        "joblib.dump(classifier, 'classifier.joblib')\n",
        "joblib.dump(pca, 'pca.joblib')\n",
        "\n",
        "print(\"훈련 완료!\")\n",
        "print(\"대표 벡터:\", representative_vector)\n",
        "\n",
        "# 검증 데이터로 성능 평가\n",
        "true_labels = []\n",
        "pred_labels = []\n",
        "\n",
        "for img_path, landmarks in test_data:\n",
        "    descriptors = encode_faces(img_path, landmarks)\n",
        "    if len(descriptors) > 0:  # 특징 벡터가 존재하는 경우에만 예측\n",
        "        reduced_descriptors = pca.transform(descriptors)\n",
        "        predictions = classifier.predict(reduced_descriptors)\n",
        "        true_labels.extend([test_labels[test_data.index((img_path, landmarks))]] * len(descriptors))\n",
        "        pred_labels.extend(predictions)\n",
        "\n",
        "# confusion matrix 출력\n",
        "cm = confusion_matrix(true_labels, pred_labels)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "# 분류 보고서 출력\n",
        "report = classification_report(true_labels, pred_labels)\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n"
      ]
    }
  ]
}